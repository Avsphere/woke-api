{"authors":[],"date_download":"2018-10-22 22:45:58","date_modify":"2018-10-22 22:45:58","date_publish":"2014-05-12 18:08:12","description":"Autonomous lethal systems, like drones, are getting more advanced. The laws have yet to catch up.","filename":"data/vaneerConsumption/ScientistsDebateKillerRobotsatUNConference.json","image_url":"https://media3.s-nbcnews.com/j/newscms/2014_20/436881/x-47b_e45c9c8c81fe19bef4d32fa2e21b2563.1200;630;7;70;5.jpg","language":"en","localpath":"/home/avsp_here/news-please-repo//data/2018/10/22/nbcnews.com/tech_security_scientists-debate-killer-robots-u-n-conference-n103406_1540248358.html","title":"Scientists Debate Killer Robots at U.N. Conference","title_page":"Scientists Debate Killer Robots at U.N. Conference","title_rss":"NULL","source_domain":"nbcnews.com","text":"Breaking News Emails Get breaking news alerts and special reports. The news and stories that matter, delivered weekday mornings.\nIt’s hard to think about autonomous, lethal machines and not imagine the killer robots from the “Terminator” movies. But could hysteria over the robo-pocalypse hold back technology that could save human lives?\nThat is the question two prominent robotics experts will debate on Tuesday, at the UN Convention on Certain Conventional Weapons (CCW) in Geneva.\nAutonomous weapons don’t feel panic or anger, meaning that if they were advanced enough, they could potentially limit civilian casualties during combat. On the other hand, computers don’t always work as planned in messy, real-life situations, not to mention they don’t have the ability to weigh ethical dilemmas in their heads.\nWhile this debate plays out, autonomous robots are only getting more advanced. Noel Sharkey, a robotics professor at the University of Sheffield, committed his career to building them for research purposes. He does not believe they belong on the battlefield.\n“My biggest concern is that when every nation has this technology, we will start seeing the full automation of warfare,” Sharkey told NBC News.\n“Some people propose that this technology will save our soldiers’ lives because we will send in machines to do our fighting for us,” he said. “But that only works if the other side does not have machines, because they will send them in to kill our soldiers.”\n“The 'Terminator' sci-fi vision is a red herring, despite its persistent use by the press.”\nIf the United States started using something like Northrop Grumman’s X-47B drone to take out targets autonomously, he said, it could start an arms race and pressure other countries into sending their own autonomous robots into battle.\nWhile Professor Ron Arkin, from the Georgia Institute of Technology, agrees with the need to be cautious, he does not think that autonomous lethal systems should be completely ruled out for future use.\n“We are not talking about systems with free will or moral agency — those will not exist anytime in the near future, if ever,” he wrote. “The “Terminator” sci-fi vision is a red herring, despite its persistent use by the press.”\nNations could limit the robots to only certain wartime scenarios and ban others altogether. Those placed in combat could come programmed with strict rules guiding their behavior.\nUltimately, he said, \"robots can potentially comply with international humanitarian law as well or better than human war fighters.”\nSharkey disagrees. Even with safeguards, he said, machines do unpredictable things when confronted with other machines, especially if they are not built by the same people.\n“Nobody knows really at all how these different systems will interact with each other,” he said.\nThere is one thing that they both agree on: The U.N. should pass a moratorium, or temporary ban, on using autonomous weapons until the international community can come to a consensus.\nRegardless of who \"wins\" the debate, U.N. delegates will be paying attention.\n\"The room will be packed tomorrow,\" Sharkey said, \"the most packed it has been for a CCW meeting ever.\"","url":"https://www.nbcnews.com/tech/security/scientists-debate-killer-robots-u-n-conference-n103406"}
